{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Microfossils, Remote Sensing, and GIS for Proxy-dating Coastal Archaeological Sites and Landscapes: A case from Minas Basin, Bay of Fundy, Canada"},{"metadata":{},"cell_type":"markdown","source":"This Jupyter Notebook is intended to replicate the production of geochronological *terminus ante quem* boundaries for the Kingsport marsh as described in the associated article. \n\nLoading this *AppendixB* Jupyter Notebook as a Binder increases reproducability of the workflow employed to create the geochronological boundaries."},{"metadata":{},"cell_type":"markdown","source":"#### Import Packages & Define Root"},{"metadata":{},"cell_type":"markdown","source":"The first step is to import the required Python packages to replicate the method presented in the associated article. \n\nThe first chunk in the following block of code imports the required packages. The first two lines of the last chunk sets environment parameters to not import layers produced in geoprocessing to the active map frame, and allow outputs to be overwritten by our Notebook. The last two lines create a variable for our the open map frame in our project so we can more easily display our final outputs in later."},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport iosacal\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport json\nimport re\nimport os\n\n\nfrom ipyleaflet import *\n%matplotlib inline\n\nfrom pprint import pprint\nfrom numpy import ones,vstack\nfrom numpy.linalg import lstsq\nfrom iosacal import R, iplot\nfrom iosacal.text import single_text\nfrom pandas import *\nfrom matplotlib import pyplot, figure","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next, the interactive map frame powered by iPyLeaflet is created by running the proceeding code block.\n\nWe define the map frame as *mapFrame* on line 1 followed by adding data and functionality: \n\n- ESRI satellite imagery basemap\n- custom map tile layer from the lidar basemaps shown in the article\n- measurement functionality\n- full screen functionality\n- scale bar\n- layer toggle functionality"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"mapFrame = Map(basemap=basemaps.Esri.WorldImagery, center=(45.1562107, -64.3699627), zoom=15, max_zoom=18)\nbasemap = LocalTileLayer(name=\"Shaded Relief\",tms = True, path=\"minasBase/{z}/{x}/{y}.png\")\nmapFrame.add_layer(basemap)\nmeasure = MeasureControl(position='topleft',active_color = 'orange',primary_length_unit = 'meters')\nmapFrame.add_control(measure)\nmeasure.completed_color = 'red'\nmapFrame.add_control(FullScreenControl(position='topright'))\nmapFrame.add_control(ScaleControl(position='topright', metric=True))\nmapFrame.add_control(LayersControl(position='topleft'))\nmapFrame","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Examine open layers"},{"metadata":{},"cell_type":"markdown","source":"The open map above displays datasets that will help explore the output surface after running this notebook. Feel free to explore the LiDAR data of Kingsport marsh."},{"metadata":{},"cell_type":"markdown","source":"## Data Preparation"},{"metadata":{},"cell_type":"markdown","source":"Following the data preparation steps outlined in the methods section of the associated article, we have placed a CSV titled **Appendix A**  within the */data* folder. The following codeblock will display the *AppendixA.csv* file as a table.\n<br><br>\nThe first line calls the CSV from the location within the project folder and loads it into a 'pandas' dataframe called *AppendixA*. Our second line defines formatting, cell alignment, and styles to be applied when we call the variable *Table*. *Table* is called in the third line and our formatted CSV is shown below."},{"metadata":{"trusted":true},"cell_type":"code","source":"AppendixA = pd.read_csv(\"./data/AppendixA.csv\")\nTable = AppendixA.style.format({\"error\": lambda x: \"±{:.1f}\".format(abs(x))}, na_rep=\"-\").format({\"date\": lambda x: \"{:.1f} C14BP\".format(float(x))}).format({\"core_depth\": lambda x: \"{:.2f}m\".format(abs(x))}, na_rep=\"-\").format({\"modern_HHW\": lambda x: \"{:.3f}m\".format(float(x))}, na_rep=\"-\").format({\"HHW_corrected\": lambda x: \"{:.3f}m\".format(float(x))}, na_rep=\"-\").format({\"modern_HHW\": lambda x: \"{:.3f}m\".format(float(x))}, na_rep=\"-\").format({\"HHW_error\": lambda x: \"±{:.2f}m\".format(float(x))}, na_rep=\"-\").set_properties(subset=[\"error\", \"core_depth\", \"modern_HHW\", \"HHW_corrected\", \"HHW_error\"], **{'text-align': 'center'}).set_properties(subset=[\"date\"], **{'text-align': 'right'})\nTable","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"CSV data in the data frame can be plotted by calling the attributes we wish to plot. The codeblock below plots the relationship of core depth to date of sample recovered from that depth in radiocarbon years."},{"metadata":{"trusted":true},"cell_type":"code","source":"date = AppendixA['date']\ndepth = AppendixA['core_depth']\n\nplt.plot(date, depth)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Radiocarbon Calibration"},{"metadata":{},"cell_type":"markdown","source":"The python package IOSACal is used in the following to calibrate the radiocarbon dates obtained from samples at Kingsport. IOSACal does not yet come with the MARINE20 or INTCAL20 calibration curves. The .14c calibration curve files were obtained from the most recent OxCal distribution and copied into the *data* folder of the IOSACal package within the custom Python environment. This ensures that we can use the newest calibration curves directly in this Notebook using Python."},{"metadata":{},"cell_type":"markdown","source":"#### Marine Resevoir Correction"},{"metadata":{},"cell_type":"markdown","source":"Now that we have our CSV holding the necessary data to begin, we need to correct for marine resevoir effect, then calibrate our radiocarbon dates. Mentioned in the associated article, the ΔR of -64 ±90 is subtracted from each radiocarbon date *before* calibration occurs. The codeblock below will perform this calculation. As per usual, when addition or subtraction between two values with reported errors, the errors are summed."},{"metadata":{"trusted":true},"cell_type":"code","source":"AppendixA[\"date\"] = AppendixA[\"date\"] - (-64)\nAppendixA[\"error\"] = AppendixA[\"error\"] + (90)\nTable","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Calibrating Sample Data"},{"metadata":{},"cell_type":"markdown","source":"The two codeblocks below will loop through the records in the above table, outputting graphics and a short report for each of the dates.<br>\n\nThe first three lines of code define the variables <i>s</i>, <i>d</i>, & <i>e</i> as values from specified columns in our dataframe (<i>ID</i>, <i>date</i>, & <i>error</i>). The following two lines initialize empty lists, *cal68* and *cal95*, that will store the minimum and maximum date of each confidence interval for each sample.<br>"},{"metadata":{"trusted":true},"cell_type":"code","source":"s = AppendixA.ID.values\nd = AppendixA.date.values\ne = AppendixA.error.values\ncal68 = []\ncal95 = []","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A lot worthy of explaination happens in the following 9 lines of code.<br>\n\nBeginning with line 1, the following text described the process of our loop line by line.<br>\n\nLine 1 is the header of our **for** loop. The header defines the parameters of our loop, and describes the conditions to be met **for** the loop to stop. Our conditions state iterate the body of the loop below **for** a number of times equal to the <b>range</b> of <b>axis</b> 0, or rows, in <i>AppendixA</i>. We have three samples, so the loop will iterate a total of three times with the provided data.<br>\n\nLine 2 begins the body of the loop by defining a variable called <i>r</i> as equal to the values of date (<i>d</i>), error (<i>e</i>), and ID (<i>s</i>). The variables are designated as radiocarbon dates with the variable <i>R</i> (shorthand in IOSACal). The <i>i</i> in square brackets following <i>d</i>, <i>e</i>, and <i>s</i> is a reference to the value of <i>date</i>, <i>error</i>, and <i>ID</i> for the record with an index matching the current iteration of the loop. The <i>r</i> variable now holds a list containing the three values for each of the three samples. <br>\n\nLine 3 passes the values of our list stored in <i>r</i> to the <b>calibrate</b> method in IOSACal. By prefixing <b>r.</b> to <b>calibrate</b> we are defining that the values in *r* will will be calibrated using the <i>marine20</i> .14c file in parentheses. The calculated values are saved in the variable <i>cal_r</i>. <br>\n\nLine 4 creates a report for the calibration, saved to the variable - <i>report</i>.<br>\n\nOn line 5, we search the output report text for digits, storing them in as a list in the variable called <b>findDigits</b>. Line 6 and 7 append the min and max values from our <b>findDigits</b> list for the 68% and 95% confidence intervals, based on their position in the list. These lines take advantage of the consistent structure IOSACal uses for reporting to allow us to directly use the outputs in further analysis.<br>\n\nLines 8 and 9 then **print** the report stored in our *report* variable below our code, and creates and saves a visualization of the calibration to the directory - */SupplementaryData/output* as a JPG image named by *ID*."},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"dir= r\"./output/\"\nfor i in range(AppendixA.shape[0]):\n    r = R(d[i], e[i], s[i])\n    cal_r = r.calibrate('marine13')\n    report = (single_text(cal_r))\n    findDigits = [int(s) for s in re.findall(r'\\b\\d+\\b', report)]\n    cal68.append(findDigits[7:9])\n    cal95.append(findDigits[13:15])\n    print(report)\n    iplot(cal_r, output = dir + s[i] + \".jpg\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cal68date = np.array(cal68)\ni = AppendixA.index.values\nfor i in range(AppendixA.shape[0]):\n    d[i] = (cal68date[i,0]+cal68date[i,1])/2\n    e[i] = (cal68date[i,0]-cal68date[i,1])/2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we can modify our formatted *Table* dataframe, and visualize the result of our calibration."},{"metadata":{"trusted":true},"cell_type":"code","source":"Table = AppendixA.style.hide_index().format({\"error\": lambda x: \"±{:.1f}\".format(abs(x))}, na_rep=\"-\").format({\"date\": lambda x: \"{:.0f} CalBP\".format(float(x))}).format({\"core_depth\": lambda x: \"{:.2f}m\".format(abs(x))}, na_rep=\"-\").format({\"modern_HHW\": lambda x: \"{:.3f}m\".format(float(x))}, na_rep=\"-\").format({\"HHW_corrected\": lambda x: \"{:.3f}m\".format(float(x))}, na_rep=\"-\").format({\"modern_HHW\": lambda x: \"{:.3f}m\".format(float(x))}, na_rep=\"-\").format({\"HHW_error\": lambda x: \"±{:.2f}m\".format(float(x))}, na_rep=\"-\").set_properties(subset=[\"error\", \"core_depth\", \"modern_HHW\", \"HHW_corrected\", \"HHW_error\"], **{'text-align': 'center'}).set_properties(subset=[\"date\"], **{'text-align': 'left'})\nTable","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Production of Geochronological Boundaries"},{"metadata":{},"cell_type":"markdown","source":"### Calculating Sample Elevation"},{"metadata":{},"cell_type":"markdown","source":"With the radiocarbon calibration complete, we can now begin to produce the geochronological *terminus ante quem* boundaries. Our first step is to calculate the elevation of the radiocarbon dated samples. These elevations will be used to derive past HHW in the CGVD2013 vertical datum.\n\nThe codeblock below subtracts *core_depth* from *modern_HHW* and places the result in the *HHW_corrected* column."},{"metadata":{"trusted":true},"cell_type":"code","source":"AppendixA[\"HHW_corrected\"] = AppendixA[\"modern_HHW\"]-AppendixA[\"core_depth\"]\nTable","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"One sample, <i>Gx-6811</i>, was located within high marsh Zone 1b. The upper limit of Zone 1b will be 20cm below the limit of HHW mesasured from the top of Zone 1a.\n\nThe errors provided for <i>Gx-6811</i> cannot be reduced, but we can correct elevation to match the marine limit by adding the 20cm range in elevation for Zone 1a to the Zone 1b sample elevation.\n\nThe codeblock below performs this correction, then displays the updated values in our <i>AppendixA</i> dataframe."},{"metadata":{"trusted":true},"cell_type":"code","source":"AppendixA.iloc[1:2,5] = AppendixA.iloc[1:2,5]+0.2\nTable","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Determining Relative Sea Level Rise"},{"metadata":{},"cell_type":"markdown","source":"Our calculated HHW values for the Kingsport sample dates are shown above.\n\nNext step is to determine the amount of RSL rise that has occurred since 1980 at the Kingsport sample locations. In order to do this, two coordinate pairs are required. Variables are defined below for our <i>x1</i>, <i>y1</i>, <i>x2</i>, and <i>y2</i> coordinates. Variable <i>x1</i> represents the radiocarbon equivalent date for the year 2020, where the value 0 is equal to the year 1950."},{"metadata":{"trusted":true},"cell_type":"code","source":"x1 = -70\nx2 = AppendixA.loc[2].at[\"date\"]\ny1 = AppendixA.loc[2].at[\"modern_HHW\"]\ny2 = AppendixA.loc[2].at[\"HHW_corrected\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We use our coordinate pairs from our table to derive the equation for the linear relationship between the most recent of the radiocarbon dated samples (*Gx-6812, HHW_corrected*) and modern HHW for that sample (*Gx-6812, modern_HHW*) following a  slightly modified codeblock [\"from Stack Overflow\"](https://stackoverflow.com/a/21566184). This equation will be used to solve for the HHW in the year 1980 by solving for x = -30 in the two following codeblocks. \n\nThe first codeblock creates an object called *coords* from our *x1, y1*, and *x2, y2* coordinate pairs of date and elevation. We then use <b>zip()</b> to sort these pairs into *x_coords* and *y_coords* lists. The third line creates the coefficient matrix (*A*) for the least squares method, <b>lstsq()</b>, on line 4. The two derived values are the slope (<i>m</i>) and intercept (<i>c</i>) of our equation, printed below."},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"coords = [(x1,y1),(x2,y2)]\nx_coords, y_coords = zip(*coords)\nA = vstack([x_coords,ones(len(x_coords))]).T\nm, c = lstsq(A, y_coords, rcond=None)[0]\nprint(\"Equation is y = {:.5f}x + {:.5f}\".format(m,c))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Our output equation is: $$y = -0.00230x + 6.63404$$<br>\n\nThe following two codeblocks perform two calculations. First, a modeled HHW elevation value is calaculated for Kingsport in 1980 by solving for <i>y</i>, where: $$x = -30$$<br>  Next, RSL rise since 1980 at HHW is calculated from the difference in HHW compared to 2020.<br>\n\nThe following codeblock can also be expressed as: $$HHW_{1980} = 0.00230(-30) + 6.63404$$<br>\n\nOur sea level rise calculation in the second codeblock is expressed as: $$RSLR_{[1980,2020]} = HHW_{2020} - (0.00230(-30) + 6.6340)$$<br>\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"SL = m * (-30) + c\n\nprint(\"Higher high water was\", \"{:.3f}m\".format(SL),\"CGVD2013 at Kingsport in 1980.\")","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"SLR = y1 - SL\nSLRcm = SLR*100\n\nprint(\"Sea level has risen\", \"{:.1f}cm\".format(SLRcm),\"since 1980 at Kingsport.\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As our <i>HHW_corrected</i> elevations for the Kingsport core samples are calculated as values for the year 2020, we need to correct the elevations to match depth below 1980 HHW. The calculation is performed in the codeblock below and expressed as: $$HHW\\_corrected_{AppendixA} = HHW\\_corrected_{AppendixA} - SLR$$"},{"metadata":{"trusted":true},"cell_type":"code","source":"AppendixA[\"HHW_corrected\"] = AppendixA[\"HHW_corrected\"] - SLR\nTable","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Calculating Equvalent HHW at Oak Point"},{"metadata":{},"cell_type":"markdown","source":"An equivalent HHW elevation at Oak Point is obtained for each calibrated date by correcting for SLR and sample elevation.\n\nAn offset value for the geochronological boundary elevations at Oak Point is provided by the difference in RSL rise for the Kingsport sample because we can expect our high-marsh indicators to increase in elevation at the rate of RSL rise. \n\nThe following codeblock calculates equivalent modern HHW elevations for Oak Point.\n\nOn line 1 the HHW value of <b>8.626</b> is used to calculate elevations for each sample subtracting <i>core_depth</i> and <i>SLR</i>. \n\nLine 2 displays the list of calculated values within <i>OakPointHHW</i>."},{"metadata":{"trusted":true},"cell_type":"code","source":"OakPointHHW = [6.826 - AppendixA.iloc[0:3,3] - SLR]\nOakPointHHW","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The following codeblock creates a new dataframe called <i>OakPoint</i> holding the calculated HHW elevations, calibrated dates, and errors at Oak Point.\n\nLine 1 creates the dataframe from our <i>AppendixA</i> dataframe.\n\nLine 2 replaces the <i>AppendixA</i> data originally in the <i>OakPoint</i> dataframe with values from the <i>OakPointHHW</i> list calculated above. \n\nLine 3 drops the unnecessary fields from the <i>AppendixA</i> dataframe.\n\nLine 4 corrects the elevation for Zone 1b at Oak Point by adding the offset of 0.2m to the elevation of the second record.\n\nLines 5 and 6 stylize out table, and display the result."},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"OakPoint = pd.DataFrame(data=AppendixA)\nOakPoint.iloc[0:3,5] = OakPointHHW[0]\nOakPoint = OakPoint.drop(['ID','core_depth','modern_HHW'], axis=1)\nOakPoint.iloc[1:2,2] = OakPoint.iloc[1:2,2] + 0.2\nOakPointTable = OakPoint.style.hide_index().format({\"error\": lambda x: \"±{:.1f}\".format(abs(x))}, na_rep=\"-\").format({\"date\": lambda x: \"{:.1f} CalBP\".format(float(x))}).format({\"HHW_corrected\": lambda x: \"{:.3f}m\".format(float(x))}, na_rep=\"-\").format({\"HHW_error\": lambda x: \"±{:.2f}m\".format(float(x))}, na_rep=\"-\").set_properties(subset=[\"error\", \"HHW_corrected\", \"HHW_error\"], **{'text-align': 'center'}).set_properties(subset=[\"date\"], **{'text-align': 'left'})\nOakPointTable","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Initial Boundary Creation"},{"metadata":{},"cell_type":"markdown","source":"The <i>OakPoint</i> dataframe, shown above, holds HHW elevations at calibrated radiocarbon date intervals derived from samples located in a slightly different area of Kingsport Marsh. A <b>for</b> loop is used to run the <b>Set Null</b> and <b>Contour</b> geoprocessing tools on each record.\n\nThe codeblock below defines the elevation surface to be used as the DEM in our active Map dataframe."},{"metadata":{"trusted":true},"cell_type":"code","source":"mapFrame","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Visualizing Drowned Forest"},{"metadata":{},"cell_type":"markdown","source":"Below you will see the code to produce a plot of surveyed locations of stumps in the drowned forest in relation to sea level rise over-time."},{"metadata":{"trusted":true},"cell_type":"code","source":"\nplt.style.use('seaborn-colorblind')\n\ndef myround(x, base=5):\n    return int(base * round(float(x)/base))\n\nx = np.array([4465, 2550, 1890, -70])\ny = np.array([-2.766, 0.434, 2.234, 6.826])\nerror = np.array([0.20, 0.55, 0.20, 0.20])\nstump = np.array([1.992, 1.868, 1.528, 1.496, 1.343, 0.648, 0.553, 0.377, 4.330, 3.379])\nstumpAge = np.array([1976.758241758242, 2022.1794871794873, 2146.7216117216117, 2158.443223443224, 2214.4871794871797, 2469.0659340659345, 2503.864468864469, 2585.688622754491, 1001.7565217391303, 1415.2347826086955])\nzErr = np.array([0.011, 0.014, 0.011, 0.012, 0.012, 0.011, 0.010, 0.010, 0.012, 0.013])\ndateErr = np.array([400, 390, 330, 0])\n\nplt.plot(x, y, 'bo', x, y, 'k-', linewidth=1.25, linestyle='dashed')\nplt.plot(stumpAge, stump, 'd', color='#4CE600', markersize=6, markeredgewidth=0.75, markeredgecolor='k')\nplt.fill_betweenx(y, x-dateErr, x+dateErr, alpha=0.4, edgecolor='#A80000', facecolor='#A83800',\n    linewidth=1.5, linestyle='dashdot', antialiased=True)\nplt.errorbar(x,y,error,dateErr, alpha=0.6, color='#1B2ACC', linewidth=0, elinewidth=1.5, ecolor='black', capsize=5)\nplt.fill_between(x, y-error, y+error, alpha=0.75, edgecolor='#1B2ACC', facecolor='#51A8C7',\n    linewidth=1.25, linestyle='dashdot', antialiased=True)\n\nplt.annotate(str(myround(stumpAge[0])),(stumpAge[0], stump[0]+0.05),(2500, 3.5),arrowprops=dict(arrowstyle = \"-\", alpha=0.9),alpha=0.85,fontweight=\"bold\",horizontalalignment=\"left\",verticalalignment=\"bottom\")\nplt.annotate(str(myround(stumpAge[1])), (stumpAge[1], stump[1]+0.05), (2700, 3.2), arrowprops=dict(arrowstyle = \"-\", alpha=0.9), alpha=0.85, fontweight=\"bold\", horizontalalignment=\"left\",\nverticalalignment=\"bottom\")\nplt.annotate(str(myround(stumpAge[3])), (stumpAge[3], stump[3]+0.05), (3050, 2.5), arrowprops=dict(arrowstyle = \"-\", alpha=0.9), alpha=0.85, fontweight=\"bold\", horizontalalignment=\"left\",\nverticalalignment=\"bottom\")\nplt.annotate(str(myround(stumpAge[4])), (stumpAge[4], stump[4]+0.05), (3200, 2.3), arrowprops=dict(arrowstyle = \"-\", alpha=0.9), alpha=0.85, fontweight=\"bold\", horizontalalignment=\"left\",\nverticalalignment=\"bottom\")\nplt.annotate(str(myround(stumpAge[5])), (stumpAge[5], stump[5]+0.05), (3400, 1.8), arrowprops=dict(arrowstyle = \"-\", alpha=0.9), alpha=0.85, fontweight=\"bold\", horizontalalignment=\"left\",\nverticalalignment=\"bottom\")\nplt.annotate(str(myround(stumpAge[6])), (stumpAge[6], stump[6]+0.05), (3550, 1.6), arrowprops=dict(arrowstyle = \"-\", alpha=0.9), alpha=0.85, fontweight=\"bold\", horizontalalignment=\"left\",\nverticalalignment=\"bottom\")\nplt.annotate(str(myround(stumpAge[7])), (stumpAge[7], stump[7]+0.05), (3700, 1.4), arrowprops=dict(arrowstyle = \"-\", alpha=0.9), alpha=0.85, fontweight=\"bold\", horizontalalignment=\"left\",\nverticalalignment=\"bottom\")\nplt.annotate(str(myround(stumpAge[9])), (stumpAge[9], stump[9]+0.05), (2100, 4.3), arrowprops=dict(arrowstyle = \"-\", alpha=0.9), alpha=0.85, fontweight=\"bold\", horizontalalignment=\"left\",\nverticalalignment=\"bottom\")\nplt.annotate(str(myround(stumpAge[8])), (stumpAge[8], stump[8]+0.05), (1750, 5.0), arrowprops=dict(arrowstyle = \"-\", alpha=0.9), alpha=0.85, fontweight=\"bold\", horizontalalignment=\"left\",\nverticalalignment=\"bottom\")\nplt.annotate(str(myround(stumpAge[2])), (stumpAge[2], stump[2]+0.05), (2900, 2.7), arrowprops=dict(arrowstyle = \"-\", alpha=0.9), alpha=0.85, fontweight=\"bold\", horizontalalignment=\"left\",verticalalignment=\"bottom\")\n\n\nplt.xticks(np.arange(0,5000, step=500))\nplt.yticks(np.arange(-4,7.5, step=0.5))\nplt.axhline(-4,color='black')\nplt.axvline(-250,color='black')\nplt.axhline(7.5,color='black')\nplt.axvline(5000,color='black')\nplt.tick_params(direction='in', length=6, width=1, colors='black',grid_color='gray', grid_alpha=0.5)\nplt.xlabel('Age (years CalBP)')\nplt.ylabel('Elevation (metres CGVD2013)')\nplt.xlim(-250, 5000)\nplt.ylim(-4, 7.5)\n\n# Show the major grid lines with dark grey lines\nplt.grid(b=True, which='major', color='#666666', linestyle='-')\n\n# Show the minor grid lines with very faint and almost transparent grey lines\nplt.minorticks_on()\nplt.grid(b=True, which='minor', color='#999999', linestyle='-', alpha=0.2)\n\nfig = plt.gcf()\nfig.set_size_inches(20, 12)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":2}